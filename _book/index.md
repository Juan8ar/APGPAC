---
title: "Introducción a la Analítica de Datos para la Gestión de Proyectos de Alta Complejidad"
author: 
- name: Juan C. Correa
  email: jcc@criticalcentrality.com
  affiliation: Critical Centrality Institute
date: "2024-01-02"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apacite
link-citations: TRUE
---
# Sobre el autor {-}
Juan C. Correa es venezolano, está casado y tiene un hijo. Es egresado de la Universidad Católica Andrés Bello como licenciado en psicología y magíster en metodología de las ciencias del comportamiento, y es doctor en ciencias de la Universidad Simón Bolívar de Venezuela. Su estancia postdoctoral fue en la Universidad de Economía y Negocios de Praga, en República Checa. Su experiencia docente se concentra en varias universidades de Colombia (en la Fundación Universitaria Konrad Lorenz, el Colegio de Estudios Superiores de Administración, Escuela Colombiana de Ingeniería Julio Garavito, Universidad del Rosario, Universidad de La Sabana) y Venezuela (en la Universidad Católica Andrés Bello, la Universidad Simón Bolívar, la Universidad Nacional Experimental Antonio José de Sucre). Ha sido invitado como conferencista en la Universidad de Economia y Negocios de Praga (República Checa), Universidad de Hamburgo (Alemania), Universidad de Granada (España), Universidad de Worcester (UK), Universidad de Norfolk (USA), Universidad Nacional de Colombia, Universidad Espíritu Santo (Ecuador), en la Sociedad Peruana de Psicometría (Perú), Universidad de las Américas (Chile), Universidad Quintana Roo, Universidad de Monterrey y Tecnológico de Monterrey (México), en el Colegio Raisoni de Ingeniería y el instituto tecnológico de Maharashtra, Universidad Mundial de la Paz (India). Ha participado y obtenido recursos financieros para la investigación en Venezuela, Colombia, República Checa e India. Su experiencia como consultor organizacional para empresas de varios sectores la ha combinado con una agenda de investigación que refleja sus intereses hacia el área de sistemas complejos, la ciencia abierta, la ciencia de datos conductuales y la analítica de datos para los negocios. Ha sido invitado como par-evaluador de cientos de artículos recibidos en decenas de revistas científicas indexadas en Web of Science o Scopus y en 2022 fue invitado como par-evaluador de proyectos de investigación y desarrollo para el área de economía y negocios organizada por la Fundación para la Ciencia y Tecnología del gobierno de Portugal. En 2023 fundó Critical Centrality Institute, una iniciativa concebida como tanque de pensamiento para ofrecer evidencia empírica sobre temas críticos de nuestra sociedad.

# Prefacio {-}

Nuestro planeta enfrenta problemas de gran complejidad en diversas industrias donde la solución con "enfoques simples" está perdiendo eficacia comparado con las soluciones de "enforques complejos". La complejidad de estas soluciones se manifiesta en los sistemas de información usados para la gestión de procesos productivos de plantas industriales, de aeropuertos internacionales con mayor tráfico aéreo, de represas hidroeléctricas o de plataformas de comercio electrónico a nivel continental.

Esta creciente complejidad tecnológica ha dado lugar al surgimiento de consorcios especializados en establecer normas y estándares para el desarrollo de tecnologías orientadas a objetos [@Colomb2006]. Este tipo de tecnologías ha establecido los cimientos sobre los cuales se relacionan el desarrollo de nuevos productos [@Ruhe2014], con herramientas de ciencia de datos e inteligencia artificial [@Russell2021]. Esta conexión se vuelve aún más evidente al considerar cómo los estándares de OMG influyen directamente en la planificación y ejecución de proyectos complejos, en los que la agilidad resalta como un elemento clave y estratégico. 

En un artículo de _Harvard Business Review_, Takeuchi y Nonaka [-@Takeuchi1986] introdujeron el término **SCRUM**, asociándolo con un enfoque ágil para aumentar la velocidad y flexibilidad en el desarrollo de productos comerciales. Cuando Schwaber [-@Schwaber1997] formalizó dicho término, expresó de manera explícita que SCRUM asume que el proceso de desarrollo de sistemas es un proceso impredecible y complicado que sólo puede describirse a grandes rasgos "como una progresión general donde se combinan herramientas y técnicas conocidas y viables con lo mejor que un equipo de desarrollo puede idear para construir sistemas". Dado que estas actividades pueden variar de un momento a otro, en el proceso se utilizan controles para gestionar el proceso y el riesgo inherente. SCRUM, entendido así, resulta un enfoque de mejora para el ciclo de desarrollo incremental iterativo orientado a objetos.

Esta concepción sobre el desarrollo ágil de proyectos se hizo factible gracias a "la arquitectura y los estándares para los objetos del negocio" que  Casanave [-@Casanave1997] describió como componentes del sistema de información que directamente representan al modelo de negocios de una empresa y que se desarrollan de manera útil empleando un paradigma de la programación computacional, conocido como **[programación orientada a objetos](https://es.wikipedia.org/wiki/Programaci%C3%B3n_orientada_a_objetos)**. Grosso modo, la programción orientada a objetos resaltan de otros paradigmas como los de programación estructurada, programación lógica y programación funcional, por orientarse a la construcción de objetos que contienen datos o atributos y comportamientos o métodos, que sirven para representar, modelar y analizar entidades y procesos industriales empleando la programación computacional.  

En cierta medida, la idea de la cuarta revolución industrial o **[Industria 4.0](https://es.wikipedia.org/wiki/Cuarta_Revoluci%C3%B3n_Industrial)**  emerge como el resultado de las diferentes aplicaciones de la progrmación orientada a objetos. Para entender el alcance de la programación orientada a objetos, basta con mencionar algunas de sus herramientas emparentadas:

- Diseño, programación y control en robótica y sistemas robóticos para procesos de manufactura [@Bison1989]

- Plataformas para el modelado y la simulación basada en agentes inteligentes [@Wooldridge1995].

- Sistemas distribuidos con estándares CORBA (i.e., "Common Object Request Broker Architecture") [@Sutherland1997].

- Sistemas para el Control Supervisorio y Adquisicón de Datos (SCADA o "Supervisory Control and Data Acquisition")

- Computación Gráfica para la visualización de datos estadísticos [@Wilkinson2012].

La relación entre CORBA y SCADA puede ayudar a entender como se vinculan estas tecnologías con propósitos y aplicaciones diferentes. CORBA es una arquitectura y un conjunto de estándares que permiten que diversos componentes de software escritos en múltiples lenguajes de programación y que funcionan en diferentes computadoras, puedan trabajar juntos. Los estándares CORBA facilitan el desarrollo de aplicaciones distribuidas en entornos heterogéneos, al permitir el intercambio de mensajes y la invocación de métodos entre objetos distribuidos a través de un dispositivo intermediario (Request Broker), que facilita la comunicación o interacción entre computadores. Por otro lado, los SCADA son utilizados para supervisar y controlar procesos industriales y sistemas complejos presentes en varios sectores industriales, tales como el sector energético, el sector de servicios de agua, el sector de transporte y el de manufactura. Estos sistemas recopilan datos en tiempo real a partir de sensores y dispositivos, y resumen estos datos a trabajadores humanos, que finalmente permiten el control remoto de dispositivos y procesos industriales, con o sin intermediarios tipo CORBA.

Estas tecnologías cuentan con fundamentos científicos que resultan válidos para el estudio de procesos físicos, químicos, biológicos, computacionales, económicos, o estocásticos a través de enfoques conceptuales, tales como las "simulaciones basadas en eventos", los "algoritmos genéticos", la "teoría de colas", la "teoría de grafos", o "la teoría de juegos", entre muchas otras. Un ejemplo concreto de estos enfoques conceptuales con herramientas tecnológicas lo proporciona el estudio de Cortés-Berruecos, Gershenson y Stephens [-@Cortes2016] quienes aplicaron la teoría de juegos en un modelo computacional de tráfico vehicular para estudiar el rendimiento del tránsito al analizar la conducta de manejo de los conductores. 

Si bien el término "**Gerencia Ágil de Proyectos**" ha estado muy vinculado a la gestión de proyectos de desarrollo de software [@Dyba2014], hoy dicho término puede extrapolarse a la gestión de proyectos que no necesariamente se vuelcan al desarrollo de software. Este libro ofrece una visión "actualizada" sobre la gestión o gerencia de proyectos, considerando las ventajas de la inteligencia artificial y la ciencia de datos para lidiar con la incertidumbre económica de nuestros tiempos. La Figura \@ref(fig:donde) ilustra en dónde debería estar situado el lector del presente libro.

<div class="figure">
<img src="DONDE.png" alt="La Analítica de Datos para la Gestión de Proyectos de Alta Complejidad" width="100%" />
<p class="caption">(\#fig:donde)La Analítica de Datos para la Gestión de Proyectos de Alta Complejidad</p>
</div>

Este libro está organizado en tres partes. La primera parte del libro se titula <u>**Usted Está Aquí**</u>. En esta parte hay una síntesis de los conceptos más importantes en la gestión de proyectos desde el punto de vista de la gestión del conocimiento ("Project Management Body of Knowledge") usualmente promovida por el [Project Management Institute](https://es.wikipedia.org/wiki/Project_Management_Institute) (PMI) desde 1987. A diferencia de lo establecido por el PMI, en esta parte del libro introducimos paulatinamente algunos elementos tecnológicos de ciencia de datos e inteligencia artificial que no son propios de la gestión del conocimiento del PMI. El lector puede advertir que estamos en presencia de un cambio de paradigma en la manera como los seres humanos gestionamos proyectos, debido en parte a los cambios de nuestra sociedad en permanente cambio y evolución.

La historia de las herramientas de cálculo o cómputo brindan una excelente comprensión de cómo ciertos dispositivos fueron útiles durante un momento específico y luego se reemplazaron por otros de mejor funcionamiento. Piense por ejemplo en la sucesión que ocurrió entre el ábaco, la calculadora mecánica, la calculadora electrónica, y las computadoras personales. Las herramientas ofimáticas tradicionales podrían verse como ábacos o calculadoras mecánicas. En cambio las herramientas conocidas como "_Entornos de Desarrollo Integrado_" (IDE por sus siglas en inglés) podrían verse como otro tipo de herramientas con un mejor vínculo con los algoritmos de inteligencia artificial y ciencia de datos disponibles en lenguajes de programación como R y Python. Estos lenguajes proveen las herramientas computacionales fundamentales para desarrollar aplicaciones que pueden transformar radicalmente la manera como gestionamos nuestros proyectos.

Llegados a este punto, muchos lectores podrán pensar que con Microsoft Copilot y su inclusión en herramientas ofimáticas como Microsoft 365, las herramientas como Word, Excel y PowerPoint seguirán manteniendo su vigencia hasta cierto punto. Las herramientas ofimáticas no van a desaparecer, pero su uso sí va a quedar más restringido, pues la incertidumbre de nuestros tiempos exige que el profesional del siglo XXI cuente con una mayor y mejor formación científica, en la cual los conceptos teóricos se plasmen en herramientas tecnológicas cuya aplicación nos permita comprender, explicar, predecir, y pronosticar, con cierto margen razonable de confianza, lo que puede ocurrir en un entorno lleno de incertidumbre.

El elemento tecnológico fundamental de este libro es una herramienta emergente llamada Rmarkdown. En la actualidad, esta es una de las herramientas favoritas para científicos de datos [@Correa2023] y expertos en inteligencia artificial [@Biecek2022] por las razones que serán evidentes para quienes quieran "probar" cómo se integran los datos, con los algoritmos computacionales y los resultados que se pueden integrar de manera ágil a reportes o informes de gran calidad. 

Según @Xie2018, RMarkdown ofrece un marco de referencia útil para la documentación de proyectos relacionados con la ciencia de datos. En este tipo de proyectos, es muy frecuente encontrar la necesidad de guardar y ejecutar syntaxis o algoritmos cuyos resultados se integren a informes de alta calidad que luego se pueden compartir con terceras partes. En efecto, RMarkdown se diseñó para facilitar la reproducción de resultados de una manera fácil y ágil que admite docenas de formatos de salida estáticos y dinámicos o interactivos.  Sin embargo, más allá de la herramienta usada para documentar, la gestión de proyectos de alta complejidad se caracteriza por la intervención de muchos colaboradores especializados que deben coordinar sus actividades para asegurar el avance del proyecto hasta su culminación exitosa. 

La segunda parte del libro, titulada <u>**Casos de Uso**</u>, se concentra en la presentación de 4 casos que reflejan la experiencia que he acumulado al trabajar con colegas científicos de datos para proyectos de vanguardia en sectores como la educación superior [@Garciachitiva2023], la salud pública [@Biecek2022], la psicología organizacional [@Zarate2023], y los servicios bancarios [@Correa2022]. 

La tercera parte del libro, titulada <u>**Gerencia de Proyectos**</u> ofrece un panorama sobre la gerencia de proyectos asistida por inteligencia artificial; o más concreta asistida por copilotos o asistentes virtuales (e.g., ChatGPT) que pueden redimenionar la gestión de proyectos en el futuro cercano. 
